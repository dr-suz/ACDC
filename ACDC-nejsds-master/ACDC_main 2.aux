\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{Xie2013,Thornton2022}
\gdef\hy@title{Approximate confidence distribution computing}
\Newlabel{c1}{$\ast $}
\newlabel{aff.a}{{1}{1}{}{address.1}{}}
\newlabel{aff.b}{{2}{1}{}{address.2}{}}
\newlabel{aff.c}{{3}{1}{}{address.3}{}}
\global\@namedef{inits@1@metadata}{S.}
\global\@namedef{snm@1@metadata}{Thornton}
\global\@namedef{inits@2@metadata}{W.}
\global\@namedef{snm@2@metadata}{Li}
\global\@namedef{inits@3@metadata}{M.}
\global\@namedef{snm@3@metadata}{Xie}
\providecommand \oddpage@label [2]{}
\gdef\hy@author{}
\gdef\hy@subject{The New England Journal of Statistics in Data Science, 2022, Volume 0, Number 0, 1}
\gdef\hy@keywords{Approximate Bayesian inference, Confidence distribution, Computational inference}
\gdef\author@num{3}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\newlabel{sec:intro}{{1}{1}{Introduction}{section.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Approximate confidence distribution computing}{1}{subsection.1.1}\protected@file@percent }
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces Accept-reject approximate confidence distribution computing (ACDC)\relax }}{1}{algocf.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{alg:rejACC}{{1}{1}{Approximate confidence distribution computing}{algocf.1}{}}
\newlabel{ACC_dist}{{1.1}{1}{Approximate confidence distribution computing}{equation.1.1}{}}
\citation{Xie2013}
\citation{Schweder2016}
\citation{Csillery2010,Cameron2012,Peters2012}
\citation{Marin2011}
\citation{Beaumont2019}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Related work on Approximate Bayesian computing (ABC)}{2}{subsection.1.2}\protected@file@percent }
\@writefile{loa}{\contentsline {algocf}{\numberline {2}{\ignorespaces Importance sampling ABC (IS-ABC)\relax }}{2}{algocf.2}\protected@file@percent }
\newlabel{alg:ISABC}{{2}{2}{Related work on Approximate Bayesian computing (ABC)}{algocf.2}{}}
\citation{marquette_statistics_2021}
\citation{Li2017}
\citation{Li2017}
\citation{Blum2010}
\citation{marjoram2003markov}
\citation{Sisson2007}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces {\it  The gray curves below represent the target posterior distribution (gray lines), $p(\theta \mid {}{x})$, for an $n=100$ IID sample from $Cauchy(\theta =10,0.55)$. The curves in black represent $q_{\varepsilon }(\theta \mid s_{obs})$ for two different summary statistics, $S_{n_1} = Median(x)$ (left) and $S_{n_2} = \mathaccentV {bar}016{x}$ (right). In each case $\varepsilon = 0.005$.} \relax }}{3}{figure.1}\protected@file@percent }
\newlabel{fig:ACC}{{1}{3}{{\it The gray curves below represent the target posterior distribution (gray lines), $p(\theta \mid \bx )$, for an $n=100$ IID sample from $Cauchy(\theta =10,0.55)$. The curves in black represent $q_{\veps }(\theta \mid s_{obs})$ for two different summary statistics, $S_{n_1} = Median(x)$ (left) and $S_{n_2} = \bar {x}$ (right). In each case $\veps = 0.005$.} \relax }{figure.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Notation and outline of topics}{3}{subsection.1.3}\protected@file@percent }
\citation{Thornton2022}
\citation{Serfling2002}
\citation{Liu1999}
\@writefile{toc}{\contentsline {section}{\numberline {2}Establishing frequentist guarantees}{4}{section.2}\protected@file@percent }
\newlabel{sec:thms}{{2}{4}{Establishing frequentist guarantees}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}General conditions}{4}{subsection.2.1}\protected@file@percent }
\newlabel{sec:main}{{2.1}{4}{General conditions}{subsection.2.1}{}}
\newlabel{eq:LR}{{2.1}{4}{General conditions}{equation.2.1}{}}
\newlabel{cond:ACC_interval}{{1}{4}{}{condition.1}{}}
\newlabel{eq:A}{{2.2}{4}{General conditions}{equation.2.2}{}}
\newlabel{eq:AB}{{2.3}{4}{General conditions}{equation.2.3}{}}
\newlabel{main1}{{1}{4}{}{lemma.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Finite sample size case}{4}{subsection.2.2}\protected@file@percent }
\citation{Cheng1949}
\citation{Li2016}
\citation{Li2017}
\citation{Li2016}
\newlabel{eq:apivot}{{2.4}{5}{Finite sample size case}{equation.2.4}{}}
\newlabel{thm:pivot}{{1}{5}{}{thm.1}{}}
\newlabel{eq:req}{{2.5}{5}{}{equation.2.5}{}}
\newlabel{cor:pivot}{{1}{5}{}{cor.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Large sample theory}{5}{section.3}\protected@file@percent }
\newlabel{sec:largeSamp}{{3}{5}{Large sample theory}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}A Bernstein-von Mises theorem for ACDC}{5}{subsection.3.1}\protected@file@percent }
\newlabel{sec:large_n_theory}{{3.1}{5}{A Bernstein-von Mises theorem for ACDC}{subsection.3.1}{}}
\newlabel{sum_conv}{{2}{5}{}{condition.2}{}}
\newlabel{par_true}{{3}{5}{}{condition.3}{}}
\citation{Li2017}
\citation{Li2017}
\citation{Li2016}
\citation{beaumont2002}
\citation{Li2017}
\newlabel{initial_upper}{{4}{6}{}{condition.4}{}}
\newlabel{initial_lower}{{5}{6}{}{condition.5}{}}
\newlabel{initial_gradient}{{6}{6}{}{condition.6}{}}
\newlabel{thm:ACC_limit_small_bandwidth}{{2}{6}{}{thm.2}{}}
\newlabel{thm2_uncertainty}{{3.1}{6}{A Bernstein-von Mises theorem for ACDC}{equation.3.1}{}}
\newlabel{thm2_ptestimate}{{3.2}{6}{A Bernstein-von Mises theorem for ACDC}{equation.3.2}{}}
\newlabel{thm:ACC_limit_large_bandwidth}{{3}{6}{}{thm.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Designing $r_{n}$}{6}{subsection.3.2}\protected@file@percent }
\newlabel{sec:rn}{{3.2}{6}{Designing $r_{n}$}{subsection.3.2}{}}
\citation{Gourieroux1993,mcfadden1989method}
\citation{wood2010statistical,fasiolo2018extended}
\@writefile{toc}{\contentsline {section}{\numberline {4}Numerical examples}{7}{section.4}\protected@file@percent }
\newlabel{sec:ex}{{4}{7}{Numerical examples}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Location and scale parameters for Cauchy data}{7}{subsection.4.1}\protected@file@percent }
\newlabel{sec:cauchy}{{4.1}{7}{Location and scale parameters for Cauchy data}{subsection.4.1}{}}
\citation{Li2016}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces {\it  Coverage proportions of confidence sets from ACDC applied to Cauchy data under five different settings. Coverage is calculated over $500$ independent runs that draw a $n=400$ IID sample from a $Cauchy(\theta = 10, \tau = 0.55)$ distribution. The Monte Carlo sample size for both algorithms is $50,000$ and the nominal coverage level in every setting is $95\%$. The last column displays the median ratio of the sizes of confidence sets from accept-reject ACDC divided by those from IS-ABC. }\relax }}{8}{table.1}\protected@file@percent }
\newlabel{EX1_results}{{1}{8}{{\it Coverage proportions of confidence sets from ACDC applied to Cauchy data under five different settings. Coverage is calculated over $500$ independent runs that draw a $n=400$ IID sample from a $Cauchy(\theta = 10, \tau = 0.55)$ distribution. The Monte Carlo sample size for both algorithms is $50,000$ and the nominal coverage level in every setting is $95\%$. The last column displays the median ratio of the sizes of confidence sets from accept-reject ACDC divided by those from IS-ABC. }\relax }{table.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces {\it  These are densities of point estimators from accept-reject ACDC (red) and IS-ABC (black) for the $500$ independent data sets for each of the five settings in Table \ref  {EX1_results}. Additionally, this figure shows a box plot of the relative sizes of the $500$ confidence sets, that is, the length (or volume) of regions produced by accept-reject ACDC divided by those of IS-ABC.}\relax }}{8}{figure.2}\protected@file@percent }
\newlabel{fig:cauchy_loc_ex}{{2}{8}{{\it These are densities of point estimators from accept-reject ACDC (red) and IS-ABC (black) for the $500$ independent data sets for each of the five settings in Table \ref {EX1_results}. Additionally, this figure shows a box plot of the relative sizes of the $500$ confidence sets, that is, the length (or volume) of regions produced by accept-reject ACDC divided by those of IS-ABC.}\relax }{figure.2}{}}
\citation{wood2010statistical}
\citation{wood2010statistical}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Mulit-parameter inference for a Ricker model}{9}{subsection.4.2}\protected@file@percent }
\newlabel{sec:ricker}{{4.2}{9}{Mulit-parameter inference for a Ricker model}{subsection.4.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces {\it  Coverage proportions of marginal confidence intervals (or joint confidence regions) for accept-reject ACDC and IS-ABC applied to Ricker data. Coverage is calculated over $150$ independent runs that produce observations from $t=51$ to $100$ for data generated by a Ricker model with $(r,\sigma , \phi )=(e^{3.8},0.3,10)$. The Monte Carlo sample size for both algorithms is $50,000$ and the nominal coverage level in every setting is $95\%$. The last column displays the median ratio of the sizes of confidence sets from accept-reject ACDC divided by those from IS-ABC.}\relax }}{9}{table.2}\protected@file@percent }
\newlabel{EX2_results}{{2}{9}{{\it Coverage proportions of marginal confidence intervals (or joint confidence regions) for accept-reject ACDC and IS-ABC applied to Ricker data. Coverage is calculated over $150$ independent runs that produce observations from $t=51$ to $100$ for data generated by a Ricker model with $(r,\sigma , \phi )=(e^{3.8},0.3,10)$. The Monte Carlo sample size for both algorithms is $50,000$ and the nominal coverage level in every setting is $95\%$. The last column displays the median ratio of the sizes of confidence sets from accept-reject ACDC divided by those from IS-ABC.}\relax }{table.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Discussion}{9}{section.5}\protected@file@percent }
\newlabel{sec:discuss}{{5}{9}{Discussion}{section.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces {\it  These are densities of point estimators from accept-reject ACDC (red) and IS-ABC (black) for the $150$ independent data sets produced by the Ricker model. Additionally, this figure shows a box plot of the ratio of the sizes of the $150$ confidence sets, that is, the length (or volume) of regions produced by accept-reject ACDC divided by those of IS-ABC. }\relax }}{10}{figure.3}\protected@file@percent }
\newlabel{fig:EX2_results}{{3}{10}{{\it These are densities of point estimators from accept-reject ACDC (red) and IS-ABC (black) for the $150$ independent data sets produced by the Ricker model. Additionally, this figure shows a box plot of the ratio of the sizes of the $150$ confidence sets, that is, the length (or volume) of regions produced by accept-reject ACDC divided by those of IS-ABC. }\relax }{figure.3}{}}
\@writefile{toc}{\contentsline {section}{Acknowledgements}{10}{section*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{Funding}{10}{section*.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{Supplementary Material}{10}{section*.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Notation}{10}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7}Conditions}{10}{section.7}\protected@file@percent }
\citation{Li2017}
\citation{Li2017}
\citation{Li2016}
\newlabel{kernel_prop}{{7}{11}{}{condition.7}{}}
\newlabel{sum_approx}{{8}{11}{